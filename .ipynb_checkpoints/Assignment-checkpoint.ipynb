{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP2002 Main Assignment\n",
    "Machine Learning and Evolutionary Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1- Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Preparation\n",
    "The forest fire datasets are CSVs with the following fields:\n",
    "<table><tr>\n",
    "    <td>Day</td>\n",
    "    <td>Month</td>\n",
    "    <td>Year</td>\n",
    "    <td>Temperature (degrees C)</td>\n",
    "    <td>RH (Relative Humidity, %)</td>\n",
    "    <td>WS (Wind speed, kmph)</td>\n",
    "    <td>Rain (Total for day, mm)</td>\n",
    "    <td>FFMC (Fine Fuel Moisture Code index)</td>\n",
    "    <td>DMC (Duff Moisture Code index)</td>\n",
    "    <td>DC (Drought Code index)</td>\n",
    "    <td>ISI (Initial Spread Index)</td>\n",
    "    <td>BUI (Buildup Index)</td>\n",
    "    <td>FWI (Fire Weather Index)</td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in forest fire datasets\n",
    "ff_region1 = pandas.read_csv(\"datasets/AlgerianFF_Region1.csv\")\n",
    "ff_region2 = pandas.read_csv(\"datasets/AlgerianFF_Region2.csv\")\n",
    "# Randomly split into testing and training data\n",
    "\n",
    "ff_combined = pandas.concat([ff_region1, ff_region2])\n",
    "# Normalise the data so that all features are in range 0-1, while also removing the year (every value is the same so it is not useful)\n",
    "scaler = MinMaxScaler()  # Range 0-1 is default\n",
    "ff_combined_inputs = scaler.fit_transform(ff_combined[[\"day\", \"month\", \"Temperature\", \" RH\", \" Ws\", \"Rain \", \"FFMC\", \"DMC\", \"DC\", \"ISI\", \"BUI\"]])\n",
    "# Randomly split into training and testing data\n",
    "ff_train_inputs, ff_test_inputs, ff_train_targets, ff_test_targets = train_test_split(ff_combined_inputs, ff_combined[\"FWI\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The datasets for the two regions were combined and then randomly split into testing and training data (as opposed to using one region for training and the other for testing) in case there are any features that are not in the dataset that differentiate the two regions which could cause the models to overfit to the training region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "# Implement normally, then experiment with different techniques of splitting the data (incl. that one that splits it into n groups and swaps between training and testing on each)\n",
    "RF_regressor = RandomForestRegressor()\n",
    "RF_regressor.fit(ff_train_inputs, ff_train_targets)\n",
    "RF_predictions = RF_regressor.predict(ff_train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alex\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "NN_regressor = MLPRegressor()\n",
    "NN_regressor.fit(ff_train_inputs, ff_train_targets)\n",
    "NN_predictions = NN_regressor.predict(ff_train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "SVM_regressor = SVR()\n",
    "SVM_regressor.fit(ff_train_inputs, ff_train_targets)\n",
    "SVM_predictions = SVM_regressor.predict(ff_train_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Assessment of Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE: 0.26804918032786906\n",
      "NN MAE: 3.3462466843851897\n",
      "SVM MAE: 1.2541914177064437\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest MAE: \" + str(mean_absolute_error(y_true=ff_train_targets, y_pred=RF_predictions)))\n",
    "print(\"NN MAE: \" + str(mean_absolute_error(y_true=ff_train_targets, y_pred=NN_predictions)))\n",
    "print(\"SVM MAE: \" + str(mean_absolute_error(y_true=ff_train_targets, y_pred=SVM_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
